{
  "hash": "4e1095938ade117d860bf67f8eee2b7e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Equity in post-HCT Survival Predictions\nabstract: >-\n  In this competition, you’ll develop models to improve the prediction\n  of transplant survival rates for patients undergoing allogeneic\n  Hematopoietic Cell Transplantation (HCT) — an important step in\n  ensuring that every patient has a fair chance at a successful outcome,\n  regardless of their background.\nauthors: \n  - name: Guillaume Gilles\n    orcid: 0009-0000-7940-9359\n    email: guillaumegilles@me.com\nbibliography: references.bib\ncitation-location: margin\nimage: header.png\ndate: 2024-09-19\ndate-modified: 2024-11-21\ncategories:\n  - Kaggle\n  - Machine Learning\n  - R\nformat:\n  html: \n    toc: true\n    toc-depth: 3\n---\n\n\n## Notebook setup\n\n\n::: {.cell .hidden}\n\n```{.r .cell-code .hidden}\n# Quarto R setup\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.2.0 ──\n✔ broom        1.0.6      ✔ rsample      1.2.1 \n✔ dials        1.2.1      ✔ tune         1.2.1 \n✔ infer        1.0.7      ✔ workflows    1.1.4 \n✔ modeldata    1.3.0      ✔ workflowsets 1.1.0 \n✔ parsnip      1.2.1      ✔ yardstick    1.3.1 \n✔ recipes      1.0.10     \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Search for functions across packages at https://www.tidymodels.org/find/\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(ranger)\nlibrary(knitr)\n\nknitr::opts_chunk$set(\n    cache = TRUE,\n    cache.lazy = FALSE,\n    warning = FALSE,\n    message =  FALSE,\n    echo = TRUE,\n    dpi = 180,\n    fig.width = 8,\n    fig.height = 5\n)\n\ntheme_set(theme_minimal())\nupdate_geom_defaults(\"rect\", list(fill = \"midnightblue\", alpha = 0.8))\nupdate_geom_defaults(\"line\", list(color = \"midnightblue\", alpha = 0.8))\nupdate_geom_defaults(\"point\", list(color = \"midnightblue\", alpha = 0.8))\n```\n:::\n\n\n## Exploratory Data Analysis\n\n### Dataset Description\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- read_csv(\"kaggle/input/equity-post-HCT-survival-predictions/train.csv\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRows: 28800 Columns: 60\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (35): dri_score, psych_disturb, cyto_score, diabetes, tbi_status, arrhyt...\ndbl (25): ID, hla_match_c_high, hla_high_res_8, hla_low_res_6, hla_high_res_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\nThe dataset consists of 59 variables related to hematopoietic stem cell\ntransplantation (HSCT), encompassing a range of demographic and medical\ncharacteristics of both recipients and donors, such as age, sex, ethnicity,\ndisease status, and treatment details.\n\nThe primary outcome of interest is event-free survival, represented by\nthe variable `efs`, while the time to event-free survival is captured by\nthe variable `efs_time`. These two variables together encode the target\nfor a censored time-to-event analysis.\n\nThe data, which features equal representation across recipient racial\ncategories including White, Asian, African-American, Native American,\nPacific Islander, and More than One Race, was synthetically generated\nusing the data generator from [synthcity](https://github.com/vanderschaarlab/synthcity),\ntrained on a large cohort of real [CIBMTR](https://cibmtr.org/CIBMTR/About)\ndata.\n\nWe have used the SurvivalGAN method, introduced in the paper \"[SurvivalGAN: Generating Time-to-Event Data for Survival Analysis](https://proceedings.mlr.press/v206/norcliffe23a.html)\"\nwhich addresses the generation of synthetic survival data with special\nconsiderations for censoring. SurvivalGAN is adept at capturing the\nintricate relationships and interactions among variables within survival\ndata and their influence on time-to-event outcomes. This generative model\nutilizes a conditional Generative Adversarial Network (GAN) framework,\nwhich is specifically tailored to address the complexities of survival\nanalysis, including the critical task of managing censored data. \n\nBy conditioning on additional information such as censoring status and\nactual survival times, SurvivalGAN effectively learns the underlying\ndistribution of the data, ensuring that the generated synthetic dataset\nretains the essential interactions among variables that are predictive\nof survival outcomes.\n\n### Data Analysis\n\n1. Transforming efs into factor\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data |>\n  mutate(efs = as.factor(efs))\n```\n:::\n\n\n2. Drop efs_time for now because there is no in test.csv\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- data |>\n  select(-efs_time)\n```\n:::\n\n\n  - preprocessing\n  - encoding bool + string\n  - normalization / standardization\n  - feature engineer\n\n## Modeling\n\n### Splitting Data Set\n\n### Evaluation Criteria\n\nThe evaluation of prediction accuracy in the competition will involve a\nspecialized metric known as the Stratified Concordance Index (C-index),\nadapted to consider different racial groups independently. This method\nallows us to gauge the predictive performance of models in a way that\nemphasizes equitability across diverse patient populations, particularly\nfocusing on racial disparities in transplant outcomes.\n\n### Concordance index\n\nIt represents the global assessment of the model discrimination power:\nthis is the model’s ability to correctly provide a reliable ranking of\nthe survival times based on the individual risk scores. It can be\ncomputed with the following formula:\n\n$C-index = \\frac{ \\sum_{{i}{j}} 1_{{T_{j}} < {T_{i}}} \\cdot }{\\sum_{{i}{j}}}$\n\nwith:\n\n- $n_{i}$, the risk score of a unit ${i}$\n- $1_{{T_{j}} < {T_{i}}} = 1$ if ${T_{j}} < {T_{i}}$ else $0$\n\n\nThe concordance index is a value between $0$ and $1$ where:\n\n- $0.5$ is the expected result from random predictions,\n- $1.0$ is a perfect concordance and,\n- $0.0$ is perfect anti-concordance (multiply predictions with -1 to get 1.0)\n\nSimilarly to AUC, $C-index = 1$ corresponds to the best model prediction,\nand $C-index = 0.5$ represents a random prediction.\n\nStratified Concordance Index\n\nFor this competition, we adjust the standard C-index to account for racial stratification, thus ensuring that each racial group's outcomes are weighed equally in the model evaluation. The stratified c-index is calculated as the mean minus the standard deviation of the c-index scores calculated within the recipient race categories, i.e., the score will be better if the mean c-index over the different race categories is large and the standard deviation of the c-indices over the race categories is small. This value will range from 0 to 1, 1 is the theoretical perfect score, but this value will practically be lower due to censored outcomes.\n\nThe submitted risk scores will be evaluated using the score function. This evaluation process involves comparing the submitted risk scores against actual observed values (i.e., survival times and event occurrences) from a test dataset. The function specifically calculates the stratified concordance index across different racial groups, ensuring that the predictions are not only accurate overall but also equitable across diverse patient demographics.\nThe implementation of the metric is wound in this notebook.\nSubmission File\n\nParticipants must submit their predictions for the test dataset as real-valued risk scores. These scores represent the model's assessment of each patient's risk following transplantation. A higher risk score typically indicates a higher likelihood of the target event occurrence.\n\nThe submission file must include a header and follow this format:\n\nID,prediction\n28800,0.5\n28801,1.2\n28802,0.8\netc.\n\nwhere:\n\nID refers to the identifier for each patient in the test dataset.\nprediction is the corresponding risk score generated by your model.\n\n### Baseline\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsplit <- initial_split(data, prop = 0.8)\ntrain <- training(split)\ntest <- testing(split)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define the random forest model\nrf_model <- rand_forest(trees = 100,\n                        mtry = 3,\n                        min_n = 5) |>\n  set_engine(\"ranger\") |>\n  set_mode(\"classification\")\n```\n:::\n\n\n#### Create a recipe \n\n::: {.cell}\n\n```{.r .cell-code}\nrf_recipe <- recipe(efs ~ ., data = train) |>\n  step_impute_mean(all_numeric_predictors()) |>       # Mean Imputation\n  step_impute_mode(all_nominal_predictors()) |>       # Mode Imputation\n  step_normalize(all_numeric_predictors())            # Normalize numeric predictors if needed\n```\n:::\n\n\n#### Create a workflow\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_workflow <- workflow() |>\n  add_recipe(rf_recipe) |>\n  add_model(rf_model)\n```\n:::\n\n\n#### Fit the model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_fit <- rf_workflow |>\n  fit(data = train)\n```\n:::\n\n\n#### Make predictions\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredictions <- rf_fit |>\n  predict(new_data = test) |>\n  bind_cols(test)\n```\n:::\n\n\n## Submission\n\nneed to bind valid$id + prediction on valid_set\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Preparing valid dataset for prediction\nvalid <- read_csv(\"kaggle/input/equity-post-HCT-survival-predictions/test.csv\")\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nRows: 3 Columns: 58\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (35): dri_score, psych_disturb, cyto_score, diabetes, tbi_status, arrhyt...\ndbl (23): ID, hla_match_c_high, hla_high_res_8, hla_low_res_6, hla_high_res_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\n# Creating a submission.csv\nsubmission <- rf_fit |>\n  predict(new_data = valid) |>\n  bind_cols(valid) |>\n  select(ID, .pred_class)  # Replace .pred_class with the name of the prediction column if needed\n\n# Rename the prediction column to match the competition's requirements\ncolnames(submission) <- c(\"ID\", \"prediction\")\n\nwrite_csv(submission, \"submission.csv\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# # Evaluate performance\n# metrics <- metrics(predictions, truth = sii, estimate = .pred_class)  # Change .pred_class to the appropriate column name\n# print(metrics)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# train_less_pciat |>\n#   mutate_if(is.character, as.factor) |>\n#  mutate(across(categorial_features, as.factor))\n\n\n# split <- data |>\n#   drop_na(sii) %>%\n#   initial_split()\n```\n:::\n\n\n## References\n\n::: {ref}\n\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}